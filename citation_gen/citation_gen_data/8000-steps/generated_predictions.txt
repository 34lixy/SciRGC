{"labels": "There has also been significant work on #OTHEREFR; #REFR, such that even 3More details about the chunk parser can be found in #OTHEREFR. input urerance speech recognizer hypothesis L I POS tagger, prepro e.,ngp p II II", "predict": "We use the Stanford POS tagger #REFR."}
{"labels": "More recently, another encoder?decoder model using an RNN was proposed in #REFR, where the decoder is conditioned on a representation of either a source sentence or a source context.", "predict": "The same idea has been applied to the evaluation of parsing performance #REFR."}
{"labels": "The idea is similar to Finkler and Neumann #OTHEREFR, though simplified for our purposes; #REFR in his VEX system also uses the method of giving sunple questions to the user (supposedly non-linguist) to learn about word is behaviour, but it is for English", "predict": "For example, #REFRb) show that using the word-to-word translation models of the SCFG-based system to model the output of a tree-to-string system results in significant improvements over the best system."}
{"labels": "In this section, we test our joint model on PKU and MSRA datesets provided by the Second Segmentation Bake-off #OTHEREFR #REFR.", "predict": "For example, #REFR applied an unsupervised approach to automatic annotation of Chinese sentences using a model of language generation."}
{"labels": "In the context of machine translation, the performance of system generally decreases with increase in the length of the sentence #REFR.", "predict": "The second-order model is a modified version of the one introduced in #REFR."}
{"labels": "We perform experiments in two benchmark semantic parsing datasets: GeoQuery #OTHEREFR and ATIS #REFR.", "predict": "The method is based on the method of #REFR, which is similar to the one described in Section 3."}
{"labels": "We used The Japanese parser KNP #OTHEREFR and The English nl-parser #REFR.", "predict": "In addition, we report results on the state-of-the-art SVM-based system, which was used by #REFR for a similar task."}
{"labels": "Different work exploits distributional information in different forms, including context clustering models #OTHEREFR; #REFR and Bayesian Formally, the position feature is the context words with its relative position to the target word. models.", "predict": "For this, we used the 1-best 2-best 3-best system of #REFR, which was trained on the data of the CoNLL-2007 shared task."}
{"labels": "There exists some work to remove noise from SMS #OTHEREFR #REFR.", "predict": "The best results are obtained by a system that uses the 1000 most frequent words in the test corpus as features #REFR."}
{"labels": "Research in summarization #OTHEREFR; #REFR has shown that, in genres with stereotypical structure, important sentences are often located at the beginning or end of paragraphs/documents.", "predict": "This is a simple, yet effective approach #REFR."}
{"labels": "#REFR used monolingual recursive autoencoders for sentiment prediction, with or without parse tree information; this was perhaps the first use of a RAAM style approach on a large scale NLP task, albeit monolingual.", "predict": "For the most recent set of models, we use the algorithm of #REFR, which was originally developed for a similar task of extracting lexical categories for English."}
{"labels": "The SMR technique works with statistical word classes #REFR instead of words themselves (particularly, we have used 200 classes in all experiments).", "predict": "We have already described our baseline model, which is a multi-class classification model, as a special case of the general model of #REFR."}
{"labels": "Other metrics were also calculated (e.g. the V-Measure #REFR, and Average Entropy #OTHEREFR), but these results were excluded due to space constraints and the fact that their plots are similar to those shown.", "predict": "The use of this model in the context of NLP has been demonstrated for the extraction of syntactic structures #OTHEREFR; #REFR."}
{"labels": "We compare our model against a state-of-the-art statistical machine translation #OTHEREFR and an averaged perceptron edit model (PTEM) with identical features #REFR.", "predict": "This is a simple and effective method for handling the lack of resources in the case of the web-based resources of #REFR."}
{"labels": "As shown in [#REFR], a referring expression must communicate enough information to be able to uniquely identify the intended referent in the current discourse context, but avoiding the presence of redundant or otherwise unnecessary modifiers.", "predict": "Our baseline system uses a similar approach to the approach used by #REFR, which was designed to improve the performance of the basic system in NLP."}
{"labels": "We evaluate our proposed model with the most commonly used metrics for coreference resolution: for the OntoNotes data sets MUC #OTHEREFR, CEAF #REFR and their average F1 as used in the CoNLL 2011 and 2012 shared tasks; for the", "predict": "This has been used in various applications such as machine translation #OTHEREFR; #REFR, word sense disambiguation #OTHEREFR."}
{"labels": "Researchers at New Mexico State University have built an automatic algorithm \\[#REFR\\] for locating and disambiguating enus terms (head nouns) in sense definitions.", "predict": "The idea is that this is a more efficient and more robust way to handle the non-projective case of the model #REFR."}
{"labels": "Such methods can achieve better performance, reaching a tagging accuracy of up to 85% on unknown words for English \\[#REFR; Weischedel et al, 1993\\].", "predict": "#REFR."}
{"labels": "Experiments on two Chinese treebanks showed that our approach outperformed the baseline system #REFR by 1.31%.", "predict": "The first is to compare our system with the system of #REFR."}
{"labels": "Most existing works on sentiment summarization focus on predicting the overall rating on an entity #OTHEREFR; #REFR).", "predict": "This model is similar to the one described in #REFR, where the system is able to learn the meaning of a word based on its position in the corpus."}
{"labels": "#REFR propose an integrated statistical parsing technique that augments parse trees with semantic labels denoting entity and relation types.", "predict": "The task is similar to that of SMT for Chinese #REFR."}
{"labels": "Some success in this area has been demonstrated via generative models #OTHEREFR, which often benefit from wellchosen priors #REFR or posterior constraints #OTHEREFR.", "predict": "The best system for English #OTHEREFR; #REFR is a model based on a treebank and a lexical resource."}
{"labels": "Much attention has recently been devoted to integer linear programming #OTHEREFR; #REFR, dependency parsing #OTHEREFR, among others.", "predict": "The use of the word alignment is a common approach to learning language models #REFR."}
{"labels": "Our framework proceeds by using the standard procedure of performing word alignment using GIZA++ #OTHEREFR and obtaining phrases from the word alignment using heuristics #REFR and subsequently scoring them.", "predict": "We also used the 150-best parses for all experiments in #REFR."}
{"labels": "Recent years have witnessed burgeoning development of statistical machine translation research, notably phrase-based #REFR and syntax-based approaches #OTHEREFR.", "predict": "The best-performing systems are those based on statistical models #OTHEREFR, #REFR, and the one based on lexicalized models #OTHEREFR."}
{"labels": "Our analysis more fully explains the positive results achieved by #REFR from reranking with prosodic features and suggests that the hypothesis that inserted prosodic punctuation breaks n-gram dependencies only partially explains the negative results of #OTHEREFR.", "predict": "The system used by #REFR is based on the model of #OTHEREFR."}
{"labels": "We tried to incorporate the binned prosodic information described in the previous subsection in a manner that corresponds as closely as possible to the way that punctuation is represented in this corpus, because previous experiments have shown that punctuation improves parser performance #REFR.", "predict": "Our model is a form of tree-to-string model #REFR."}
{"labels": "Measures of cross-language relatedness are useful for a large number of applications, including cross-language information retrieval #OTHEREFR, cross-language annotation and resource projections to a second language #REFR.", "predict": "The SMT system we used is the same as in #REFR."}
{"labels": "We distinguish social acts from?social events? as described in #REFR: social events correspond to types of interactions among people, whereas a social act is associated with a fine-grained social goal and reflected in the specific choices of words and orthographic or prosodic cues at the level of a turn", "predict": "To solve this problem, we adopt a maximum entropy-based approach #REFR."}
{"labels": "We used 600 million Japanese Web pages #OTHEREFR parsed by KNP #REFR as a corpus.", "predict": "In this paper, we present a novel approach to the task of identifying the meaning of text using the same approach of #REFR."}
{"labels": "While syntactical constraints have been proven to helpful in identifying good paraphrases #REFR, it is insufficient in our task because it cannot properly filter the candidates for the replacement.", "predict": "A number of research efforts have been focused on the application of NLP techniques to speech recognition, including the use of word-aligned corpora #OTHEREFR; #REFR, word alignment #OTHEREFR."}
{"labels": "Our approach can be considered a generalization of syntactic approaches to example-based machine translation #OTHEREFR; #REFR.", "predict": "We use the Stanford Parser #REFR to obtain the POS tags of the sentences."}
{"labels": "A general abstract model of incremental processing based on buffers and a processor was developed by #REFR and is illustrated in Figure 2.", "predict": "We use the Stanford Parser #REFR to parse the English sentence, and the Stanford Parser #OTHEREFR to parse the German sentence."}
{"labels": "We also compare our method against Wang and #REFR?s Naive-Bayes Support Vector Machine (NBSVM), which has achieved state-of-the-art results (or close to it) on many datasets, and find that it performs competitively against NBSVM.", "predict": "The second group of methods has been based on a model of language production #OTHEREFR; #REFR."}
{"labels": "The proposal in this paper is grounded on the heterogeneity property of evaluation measures introduced in #REFR.", "predict": "We compare our approach with two state-of-the-art approaches: a state-of-the-art system for syntactic parsing (Bjo?#REFR, and a system for semantic parsing using the HMM approach described in #OTHEREFR."}
{"labels": "The first task is to answer the closest-opposite questions from the GRE test provided by #REFR4.", "predict": "We also compare with the state-of-the-art method by #REFR."}
{"labels": "However, there are state-of-the-art unlexicalized parsers #REFR, to which we believe our binarization can be applied.", "predict": "We used the SMT system described in #REFR."}
{"labels": "Examples of such systems include tutoring systems, intelligent assistants, and spoken translation systems #REFR.", "predict": "The second method is based on the idea of adding an additional feature to the feature space of the tagger #REFR."}
{"labels": "There has been a substantial body of work on metaphor identification and interpretation #OTHEREFR; #REFR.", "predict": "Our results on the CoNLL-X shared task on dependency parsing are similar to those reported by #REFR."}
{"labels": "For a fair comparison, all aligners are trained on the same training corpora described in Section 3.2. berkeley aligner #REFR applies the co-training approach for training the IBM model 1 and HMM.", "predict": "#REFR show that using the HMM approach with a different feature set for language modeling can lead to better performance."}
{"labels": "It is worth noting that the German parse trees #REFR tend to be broader and shallower than those for English.", "predict": "For the 1-best list, we follow #REFR and define the number of best candidates as? (1+2)?????????????????"}
{"labels": "We identify and eliminate unimportant words, somewhat similar to Q&A retrieval #REFR.", "predict": "#REFR used word-aligned corpora to identify words that occur in different languages."}
{"labels": "BBN has developed a software package, the Learner, as a porting tool for non-expert users #REFR.", "predict": "The model is similar to the one proposed by #REFR."}
{"labels": "We proposed a variant of an online learning algorithm inspired by a batch learning algorithm of #REFR.", "predict": "In addition, #REFR developed a system for automatic detection of the relation between word senses and the corresponding concepts, using the same method."}
{"labels": "#REFR derive paraphrases from monolingual data using distributional similarity metrics.", "predict": "A related line of work involves the use of the output of a machine learning model to predict the semantic similarity of a pair of sentences #REFR."}
{"labels": "Recently, there have been many advances in SRL #OTHEREFR; #REFR.", "predict": "This work is closely related to the work by #REFR, who showed that the same approach is effective for the task of identifying the number of instances of a word in a document."}
{"labels": "However, some recent approaches have explored ways of using annotated non-native text either by incorporating error-tagged data into the training process #OTHEREFR, or by using native language-specific error statistics #REFR.", "predict": "#REFR present a method for learning word segmentations based on the parse trees."}
{"labels": "Statistical Machine Translation #OTHEREFR and prediction of twitter responses #REFR.", "predict": "For the?x? (x, y )-function, we use the?x? function #REFRb) as an alternative."}
{"labels": "Researchers have paid a lot of attention to datadriven dependency parsing in recent years #REFR.", "predict": "The most common way of addressing this problem is to use word-level features, as described in #REFR."}
{"labels": "The unsupervised data that we integrate has been created by automatic translations of parts of the Arabic LDC Gigaword corpus (mostly from the HYT collection) with a standard phrase-based system #REFR.", "predict": "#REFR used a semi-supervised approach to extract lexicalized semantic roles from a corpus of English-to-German and German-to-English translation pairs."}
{"labels": "Although this approach can give inaccurate estimates, the counts given to the incorrect senses will disperse randomly throughout the hierarchy as noise, and by accumulating counts up the hierarchy we will tend to gather counts from the correct senses of related words #REFR.", "predict": "1304 97.85 #REFR"}
{"labels": "Our projection procedure resembles unsupervised text categorization #REFR, with categories represented by term clusters that are not predefined but rather emerge from the analyzed data:", "predict": "#REFR proposed a framework for generating the best possible parse of a sentence."}
{"labels": "A similar idea is proposed by #REFR for producing high precision data for lexical acquisition.", "predict": "This is not always the case #REFR."}
{"labels": "At each step of the distant supervision process, we closely follow the recent literature #OTHEREFR; #REFR.", "predict": "In #REFR, the system uses a 15-gram model to predict a word pair (e.g.,?a,b?) in the context of a sentence."}
{"labels": "Discourse parsing tries to identify how the units are connected with each other and thereby uncover the hierarchical structure of the text, from which multiple NLP tasks can benefit, including text summarization #OTHEREFR, sentence compression #REFR or questionanswering #OTHEREFR.", "predict": "#REFR proposed a statistical method for the extraction of word pairs."}
{"labels": "The existence of the ATIS database #REFR is no doubt a factor in the popularity of the travel domain among the research community for exactly this reason.", "predict": "We use the following features: 1. #REFR?s 3-gram language model, and 2."}
{"labels": "The graphbased method views the problem as finding an optimal tree from a fully-connected directed graph #OTHEREFR; #REFR, while the transition-based method tries to find a highest-scoring transition sequence that leads to a legal dependency tree #OTHEREFR.", "predict": "#REFR used word alignments to generate a 1-best list of sentences."}
{"labels": "We use a common graph-based parsing technique #REFR; the approaches described here could be used in transition-based parsing as well.", "predict": "The use of a large corpus for the evaluation of the model is important because the model can be trained with a very small amount of data, while the data is often difficult to obtain #REFR."}
{"labels": "This is a variant of the greedy one-to-one mapping scheme of #REFR.8 With a Tag Dictionary We also ran a second version of each experimental configuration, where we used a tag dictionary to restrict the possible path sequences of the HMM during both learning and inference.", "predict": "In the context of statistical machine translation, it is common to use a language model as a pre-processing step, and then apply a statistical model to the translation of the source sentence #OTHEREFR; #REFR."}
{"labels": "First, we investigate the impact of using different flavours of Covington?s algorithm #OTHEREFR for nonprojective dependency parsing on the ten different languages provided for CoNLL-X Shared Task #REFR.", "predict": "This model has been successfully applied to a number of tasks, including word sense disambiguation #OTHEREFR, and parsing #REFR."}
{"labels": "#REFR presents a detailed overview that also mentions short-comings.", "predict": "The work by #REFR is a more detailed, general and extensive analysis of the problem."}
{"labels": "#REFR chose an approach motivated by the assumption that documents containing a large number of patterns already identified as relevant to a particular IE scenario are likely to contain further relevant patterns.", "predict": "#REFR, for example, proposed a new algorithm for the classification of syntactically-tagged sentences."}
{"labels": "Finally, another soft-constraint approach that can also be viewed as coming from the data-driven side, adding syntax, is taken by #REFR.", "predict": "For example, #REFRb) reported an accuracy of 73.7% for the task of extracting the most likely sentence for a given sentence pair."}
{"labels": "The artificial data set of #REFR is widely used in the literature and enables comparison of a new segmentation method with existing ones.", "predict": "We use the same set of features as #REFR."}
{"labels": "Another WSD approach incorporating context-dependent phrasal translation lexicons is given in #REFR and has been evaluated on several translation tasks.", "predict": "In addition, we also compared the performance of the models in a more realistic setting, where the system is used to learn from the training corpus for a new language, for which there is no parallel corpus available #REFR."}
{"labels": "Analogous techniques for tree-structured translation models involve either allowing each nonterminal to generate both terminals and other nonterminals #REFR, or, given a constraining parse tree, to?flatten? it #OTHEREFR.", "predict": "#REFR have shown that the introduction of a simple phrase-based model, which includes a set of rules, can be an effective way to model the word order."}
{"labels": "In the Second International Chinese Word Segmentation Bakeoff (the second SIGHAN CWS bakeoff) #REFR, two of the highest scoring systems in the closed track competition were based on a CRF model #OTHEREFR.", "predict": "The most commonly used approach to extract semantic relations is the co-occurrence of words in the same sentence #REFR."}
{"labels": "The most representative methods for relation classification use supervised paradigm; such methods have been shown to be effective and yield relatively high performance #OTHEREFR; #REFR.", "predict": "#REFR present a method to extract coreference pairs from word alignments."}
{"labels": "We avoid the construction of (Bar-Hillel 1This problem is also relevant to other areas of statistical NLP, for example NL generation #REFR.", "predict": "#REFR use a combination of?unsupervised? and?supervised? techniques to learn the syntactic structure of a large set of texts."}
{"labels": "The MaltParser system for English described in #REFR was used as a baseline, and then optimized for this new task, focusing on feature selection.", "predict": "The approach we adopted is similar to that described in #REFR."}
{"labels": "There are two dominant approaches to dependency parsing: graph-based and transition-based, where graphbased parsing is understood to be slower, but often more accurate #REFR.", "predict": "The best system in the 2006 shared task #REFR, which uses a model that is very similar to the one used here, uses 100,000 features for a single sentence, which is much larger than the feature size of the system we used."}
{"labels": "Whereas we have concentrated on determinism in this paper, one can also introduce a limited degree of nondeterminism and allow some of the most promising configurations at each input position to compete, applying techniques such as beam search #OTHEREFR, or A? search #REFR in order to keep the", "predict": "The first-order model is the best known model for the task of learning word-to-word translation rules #REFR."}
{"labels": "We carried out a comprehensive evaluation of the automatically acquired verbal semantic forms against the COMLEX Resource #REFR for the 2992 active verb lemmas that both resources have in common.", "predict": "We used the training and development data from the CoNLL shared task on SMT, the development set of the CoNLL 2008 shared task on dependency parsing #REFR, and the test set of the CoNLL 2008 shared task on dependency parsing #OTHEREF"}
{"labels": "Figure 2: A simple lexicalized parse tree. criminative models described in #OTHEREFR, the generative model in #REFR, the lexicalized TAG extractor in #OTHEREFR.", "predict": "#REFR presents a method for identifying the most frequent word in a document using a 1-gram language model."}
{"labels": "More recently, we show that our SCFG-based parser can be inverted to produce a state-of-the-art NL generator, where a formal MRL is translated into an NL #REFR.", "predict": "This approach has been shown to be effective in the context of machine translation #REFR."}
{"labels": "Abstracting from results for concrete test sets, #REFR try to identify statistical and linguistic properties on that the performance of similarity metrics generally depends.", "predict": "This work is similar to the work by #REFR, who also focus on the use of an automatic parser to extract sentence-level semantic roles."}
{"labels": "We will extend the logical engine used to infer rhetorical relations--DiCE #OTHEREFRb, #REFR--to model inferences about intentional structure and its interaction with informational structure.", "predict": "We used the?time-based? model of #REFR."}
{"labels": "Some of these techniques have been successfully applied for NLP tasks: word sense disambiguation #REFR, sentiment analysis #OTHEREFR, to name but a few.", "predict": "The most common approach is to use a phrase-based model #OTHEREFR; #REFR."}
{"labels": "To expand our lexicon of these nouns, we started with a seed set garnered from the Penn Treebank #REFR, which uses distinctive tree structures for complement-taking nouns, and a small list of linguistically prominent nouns.", "predict": "The most commonly used algorithm for the construction of the feature set is the perceptron #REFR."}
{"labels": "#REFR use a thesaurus to aid in the construction of a sentiment lexicon for English.", "predict": "The first is a method for automatic acquisition of?class? labels for sentence pairs from a large corpus #REFR."}
{"labels": "Analyses have shown that this augmented data can lead to better statistical estimation or word coverage #REFR.", "predict": "We use the same feature set as in #REFR."}
{"labels": "In several studies (e.g., #REFR it has been shown that relatively unsupervised and language-independent methods could be used to generate many thousands of sets of words whose semantics is similar in some sense.", "predict": "For instance, #REFRb) have shown that the phrase structure model can be used for learning semantic parsers."}
{"labels": "In this study we use PropBanked versions of the Wall Street Journal (WSJ) part of the Penn Treebank #REFR and part of the Brown portion of the Penn Treebank.", "predict": "In this paper we show that we can use a maximum entropy model to estimate the probability of a sentence given the word-level translation, while the word-level translation can be estimated with a maximum entropy model #REFR."}
{"labels": "More recently, various researchers have used topic models for document geolocation #OTHEREFR; #REFR or other types of geographic document summarization #OTHEREFR.", "predict": "We also applied the HMM-based system described in #REFR to our system."}
{"labels": "#REFR implement lexicalized content models that represent global text properties on news articles and narratives using Hidden Markov Models (HMMs).", "predict": "We use the data from the CoNLL shared task on sentiment analysis #REFR."}
{"labels": "The merging procedure seeks to address overfitting at the level of the features themselves and remain true to the spirit of the maximum entropy approach, which seeks to represent what is unknown about the data with uniformity of the distribution, rather than by making adjustments on the model distribution itself, such as the Gaussian prior of #REF", "predict": "The system used in this paper is the system described in #REFR."}
{"labels": "Recent experiments performed by two groups of researchers at CMU have gathered ata on subjects using speech recognizers in office-like environments #REFR.", "predict": "In this paper, we report on the results of the test set of the CoNLL shared task on dependency parsing #REFR."}
{"labels": "A source of statistics widely used in prior work is the query log #OTHEREFR; #REFR.", "predict": "2We use the Stanford tagger #REFR."}
{"labels": "Details about the speech recognition system we refer to in the paper can be found in #REFR/1).", "predict": "To obtain the list of the most frequent words, we use the Stanford word sense disambiguation system #REFR."}
{"labels": "As using complementary information has been useful in, e.g., POS error detection #REFR, we explore other simple comparable properties of a dependency grammar.", "predict": "#REFR)."}
{"labels": "The linguistic information within this track is encoded in a so-called VIT 2 #REFR which is a formalism following DRT.", "predict": "#REFR)."}
{"labels": "#REFR adopted a supervised learning technique to search for useful syntactic patterns as contextual clues.", "predict": "2.3.1 Semantic Parsing We use the same system as in #REFR."}
{"labels": "For more expressive, linguistically-motivated syntactic MT models #REFR, the grammar complexity has grown considerably over hierarchical phrase-based models #OTHEREFR.", "predict": "The algorithm was tested on the same data as in #REFR, and was found to perform well."}
{"labels": "Not surprisingly, some degree of disambiguation is needed to carry out effective anonymization #REFR.", "predict": "#REFR proposed a method to detect the relationship between a word and a relation in a corpus."}
{"labels": "A good example of work in this space is shown in #REFR, who describe a method for phrase table reduction, sometimes substantial (>90%), with no impact on the resulting BLEU scores.", "predict": "#REFR proposed a method for learning an axification strategy from a large corpus of 2250 sentences of English."}
{"labels": "Factored models #REFR factor the phrase translation probabilities over additional information annotated to each word, allowing for text to be represented on multiple levels of analysis.", "predict": "The first step is to define a sentence level NER task #REFR, where each sentence is assigned to one of several classes based on the word-sense and sentence-level features."}
{"labels": "Therefore, we were less concerned with improving efficiency, and more with the properties of this algorithm, which we consider a baseline method upon which more sophisticated techniques such as best-first parsing #OTHEREFR or A search #REFR may well be able to improve.", "predict": "We use the same features as in #REFR, which we describe in detail below."}
{"labels": "It has been shown that accurate discourse segmentation within a sentence greatly improves the overall parsing accuracy to near human levels #REFR.", "predict": "#REFR introduced a phrase-based SMT system that uses a phrase-based model to perform the translation."}
{"labels": "Many systems use binary features i.e. the word-internal features, which indicate the presence or absence of particular property in the word. #OTHEREFR; #REFR.", "predict": "This is a common approach to word alignment #REFR."}
{"labels": "This 5All statistical significance tests in these experiments use the computationally-intensive randomisation test described in #REFR, with p < 0.05. work has shown that tag sequences can be successfully used to restrict the set of parses produced, but generally are not discriminatory enough to distinguish a single", "predict": "In #REFR, the same approach was applied to the task of detecting verb and noun pairs in a corpus of news articles."}
{"labels": "Segmentation is a useful intermediate step in such applications as subjectivity analysis #REFR, automatic summarization #OTHEREFR and others.", "predict": "The model is similar to the one described by #REFR."}
{"labels": "#REFR dissected parsing difficulty metrics (including surprisal and entropy) to separate out the effects of syntactic and lexical difficulties, and showed that these new metrics are strong predictors of reading difficulty.", "predict": "The results are shown in Table 1. (Bjo?#REFR used the SVM classifier with the best results in this paper."}
{"labels": "Sentence splitting and tokenization was carried out using the relevant modules from the BRAT package #REFR.", "predict": "In addition, we also compared the performance of our model to the method of #REFR."}
{"labels": "AL has been successfully applied to a number of NLP tasks such as part-of-speech tagging #OTHEREFR, and named entity recognition (NER) #REFR.", "predict": "This approach has been shown to perform well for a variety of natural language tasks #OTHEREFR; #REFR."}
{"labels": "#REFR showed a slight improvement in parsing accuracy when enough fragments were added to learn enrichments beyond manual refinements.", "predict": "The use of a large number of training data is an important feature of recent NLP systems #REFR."}
{"labels": "There is currently support for Word- Net #OTHEREFR, and UBY #REFR, which provides access to WordNet, Wikipedia, Wiktionary, GermaNet, VerbNet, FrameNet, Omega- Wiki, and various alignments between them.", "predict": "We compare our approach to that of #REFR, who used a phrase-based model for the translation process."}
{"labels": "We follow the approach of #REFR and predict the VDR y of an image over a collection of labelled region annotations x.", "predict": "The same approach was applied to the SMT system of #REFR."}
{"labels": "Handcrafted rules #OTHEREFR; #REFR for preordering training data and system input have been explored in numerous publications.", "predict": "The most popular approach is to extract semantic classes from parallel corpora #OTHEREFR; #REFR."}
{"labels": "#REFR found several parsing-based features and part-of-speech based features to be useful.", "predict": "In the context of natural language processing, many approaches have been developed for the acquisition of semantic information #OTHEREFR; #REFR."}
{"labels": "Among recent op performing methods are Hidden Markov Models #REFR, maximum entropy approaches #OTHEREFR.", "predict": "In the previous paper #REFR, we introduced a feature function for word segmentation."}
{"labels": "The reordering metrics require alignments which were created using the Berkeley word alignment package version 1.1 #REFR, with the posterior probability to being 0.5.", "predict": "The first set of experiments was performed using the Stanford Parser #REFR on the English corpus of the CoNLL-2007 shared task #OTHEREFR."}
{"labels": "FEDA is known to not improve upon a single classifier baseline for that dataset #REFR.", "predict": "In addition, we can compare with the best-performing systems from the CoNLL shared task #REFR."}
{"labels": "Many authors (among them #REFR incorporate RA into their parsing systems, yet none rely on it solely, integrating it instead with disambiguation preferences derived from word/constituent/concept ooccurrence based.", "predict": "To this end, we use the Stanford parser #REFR for parse tree extraction."}
{"labels": "Nevertheless, we conclude that among currently available approaches, i.e., our two algorithms and the EM-based approach of #REFR,?familiarity maximization? is the most promising approach for automatic assignments of heads in treebanks.", "predict": "To overcome this problem, we use a method based on?time-based methods? of #REFR."}
{"labels": "Using higher order LMs to improve the accuracy of SMT is not new. #REFR built 5-gram LMs over web using distributed cluster of machines and queried them via network requests.", "predict": "#REFR proposed a?new? method for finding the optimal parse tree by using the output of a treebank parser."}
{"labels": "This is perhaps unsurprising, as the finer-grained distinctions in corpora seem to be based on lexical properties more than on additional context (see, e.g., #REFR.", "predict": "This is in contrast to the method of #REFR, who use a maximum entropy model to train the model."}
{"labels": "The system translates entences in the ATIS domain #REFR between English and Mandarin Chinese.", "predict": "This is an example of a simple algorithm, where we have a simple rule for selecting the most likely translation from the candidate list of translations #REFR."}
{"labels": "We took the model of #REFR as the baseline, and extended it with online large-margin training and an N -gram language model.", "predict": "In the context of the coreference resolution task, #REFR used a semi-supervised learning approach."}
{"labels": "In order to improve QA systems? performance many research focus on different structures such as question processing #REFR, information retrieval #OTHEREFR for ranking, answer extraction, etc.", "predict": "This problem is also related to the problem of learning semantic representations from a corpus #OTHEREFR; #REFR."}
{"labels": "For language acquisition, a natural question is whether prosody could similarly aid grammar induction from speech #REFR.", "predict": "The first, #REFR, uses a simple treebank for the development and test sets, and then uses a model for the production of the target sentence."}
{"labels": "While many works #OTHEREFR view the properties of positivity and negativity as categorical (i.e., a term is either positive or it is not), others #REFR view them as graded (i.e., a term may be positive to a certain degree), with the underlying interpretation varying from", "predict": "The language model is trained using the same data as in #REFR."}
{"labels": "Because our algorithm does not consider the context given by the preceding sentences, we have conducted the following experiment to see to what extent the discourse context could improve the performance of the wordsense disambiguation: Using the semantic concordance files #REFR, we have counted the occurrences of content words which previously appear in the same", "predict": "The 2006 C&C #OTHEREFR, and the 2007 C&C #REFR."}
{"labels": "One source of constraint which our model still does not explicitly capture is the first-order dependency between alignment positions, as in the HMM model #REFR and IBM models 4+.", "predict": "This approach has been successfully applied to the task of parsing Chinese word alignment #OTHEREFR; #REFR."}
{"labels": "Analysis In order to distinguish antonyms from synonyms, the polarity inducing LSA (PILSA) model #REFR takes a thesaurus as input.", "predict": "In #REFR, the use of 1000 words of English for training and development is used."}
{"labels": "Given a bilingual corpus, we use GIZA++ #REFR as word alignment core algorithm.", "predict": "#REFR also report the results for the task of phrase-based translation in the same way as we do."}
{"labels": "Several researchers explored joint DS and PS information to enhance the quality of syntactic parsing #REFR.", "predict": "In addition to the two most common models of SMT, we present a new model, the?word alignment model? #REFR."}
{"labels": "We compare against the original MIML-RE model using the same dataset and evaluation methodology as #REFR.", "predict": "For example, #REFR use a small set of word types as features."}
{"labels": "4 Here I propose what appears to me to be the most direct probabilistic generalization of lexiealized TAG; a different treatment can be found in \\[#REFR\\].", "predict": "The first one is a method for learning word alignments based on word similarity #REFR."}
{"labels": "It is a fundamental and often a necessary step before linguistic knowledge acquisitions, such as training a phrase translation table in phrasal machine translation (MT) system #REFR, or extracting hierarchial phrase rules or synchronized grammars in syntax-based translation framework.", "predict": "#REFR)."}
{"labels": "#REFR took the approach that large number of entities will be unlinkable, as there is a probability that the relevant KB entry is unavailable.", "predict": "The algorithm is based on the model described in #REFR."}
{"labels": "The field of syntactic parsing has received a great deal of attention and progress since the creation of the Penn Treebank #OTHEREFR; #REFR.", "predict": "In this paper we focus on the problem of finding the most appropriate word in a given sentence #OTHEREFR; #REFR."}
{"labels": "Greedy local search #OTHEREFR; #REFR has typically been used for decoding in shift-reduce parsers, while beam-search has recently been applied as an alternative to reduce error-propagation #OTHEREFR.", "predict": "We evaluate our approach by comparing the performance of the two methods with the state-of-the-art state-of-the-art methods of #REFR and #OTHEREFR."}
{"labels": "This representation departs from the vector space metaphor #OTHEREFR; #REFR, commonly employed in other frameworks for distributional semantics such as LSA #OTHEREFR.", "predict": "In this work we propose a new approach to the problem of sentence compression, based on a statistical model of semantic roles, similar to the one proposed by #REFR."}
{"labels": "Since Japanese does not delimit words by white-space, the unit of chunking can be a character #REFR or a morpheme #OTHEREFR.", "predict": "The approach of #REFR is to use a set of features for each word in a document, which are obtained by solving a linear optimization problem."}
{"labels": "#REFR first identified the importance of syntactic query/corpus parsing for information retrieval, but did not consider query segmentation itself.", "predict": "For example, #REFR report a significant improvement in accuracy for sentence segmentation when using a small number of features."}
{"labels": "One focusses on filtering the extracted hierarchical rules either by removing redundancy #OTHEREFR or by filtering rules based on certain patterns #REFR, while the other stream is concerned about alternative approaches for learning the synchronous grammar #OTHEREFR.", "predict": "#REFR proposed a method to train a word alignment model based on a set of sentence pairs, where each pair contains two sentences with a different alignment."}
{"labels": "Rather than using sentence length as a proxy, measures can employ tools for automatic analysis of the syntactic structure of texts (e.g., #REFR).", "predict": "The second set of experiments, which focus on the case of the coreference resolution task, is based on the?time-based? algorithm described by #REFR."}
{"labels": "Sentence compression is typically formulated as the problem of removing secondary information from a sentence while maintaining its grammaticality and semantic structure #OTHEREFR; #REFR.", "predict": "For example, #REFR, for the English- Spanish language pair, use a 1-best algorithm to find the best translation from the target sentence."}
{"labels": "Features We have designed rather simple features based on the common feature set #OTHEREFR; #REFR for bunsetsu-based parsers.", "predict": "The task of automatic topic classification is also an important problem in the topic modeling community, which is similar to the problem of automatic topic segmentation in #REFR."}
{"labels": "Each list contained the n-best translations produced by the phrase-based system of #REFR.", "predict": "A large body of research on topic modeling has been conducted #OTHEREFR; #REFR."}
{"labels": "In the following model, summarized here from the full description given in #REFR, we consider words to be ordered pairs consisting of a surface word, W, and a word feature, F, given as < W, F >.", "predict": "We used the Stanford tagger #REFR to identify the syntax of the sentences in the corpus."}
{"labels": "However, although it is standard practice in MT evaluation to measure increases in automatic metric scores with significance tests #OTHEREFR; #REFR, this has not been the case in papers proposing new metrics.", "predict": "The use of the same data for the 10-best translation systems and the best translation system in the 2007 shared task #REFR."}
{"labels": "For example, it has been shown that grammatical error detection systems with high precision maximize learning effect, and that systems with high precision but lower recall are more useful in language learning than systems with high recall and lower precision #REFR.", "predict": "Our approach is similar to that of #REFR."}
{"labels": "The correctness of fields extracted via a conditional random field extractor has been shown to correlate well to an estimate obtained by a constrained forward-backward technique #REFR.", "predict": "The system has been tested on the 30000-word corpus of the CoNLL-X shared task on dependency parsing #REFR, and is now ready for use."}
{"labels": "Previous work has shown that within a given discourse #OTHEREFR, or with respect to a given collocation #REFR, a word appears in only one sense.", "predict": "The feature weights were tuned with MERT #REFR on the development set using the standard MERT training procedure."}
{"labels": "Instead researchers condition parsing decisions on many other features, such as parent phrase-marker, and, famously, the lexical-head of the phrase #OTHEREFR; #REFR (and others).", "predict": "#REFR."}
{"labels": "In particular, each of/#REFR/,/Kuhns 1988/, and/Rau and Jitcobs 1988/ describes ystems that characterize news reports with results that could llOt be obtained by keyword methods alone.", "predict": "To solve this problem, we proposed a new method for automatic automatic extraction of phrase-based translation rules #REFR."}
{"labels": "Unlike the typical content specification modules #OTHEREFR; #REFR, our system relies on an authoring workstation environment equipped with a knowledge elicitation scenario for joint humancomputer content specification #OTHEREFR, for the details of the knowledge elicitation scenario).", "predict": "We use the Stanford Parser #REFR for training and development and the Stanford Parser #OTHEREFR for testing."}
{"labels": "Approaches to this problem began by taking all fragments Fall in a treebank #OTHEREFR; #REFR.", "predict": "To reduce the size of the training data, we used a maximum entropy model to model the distribution of the input words #REFR."}
{"labels": "The smoothing methods proposed in the literature #OTHEREFR, and distance-weighted averaging #REFR.", "predict": "We use the MERT algorithm #REFR for training the model."}
{"labels": "Such annotated resources are scarce, expensive to create and even the largest of them tend to have low coverage #REFR, motivating the need for unsupervised or semi-supervised techniques.", "predict": "In recent years, the field of NLP has seen the development of many different types of tasks that can be addressed using various statistical and machine learning techniques, including parsing #OTHEREFR; #REFR, word sense disambiguation #OTHEREFR."}
{"labels": "It is highly effective for learners to receive feedback on their essays from a human tutor #REFR.", "predict": "In #REFR, the word sense disambiguation task was performed using the phrase-based SMT system."}
{"labels": "A review of methods for word sense disambiguation is presented by Ide and colleagues #REFR.", "predict": "In this work, we used a treebank that was produced by the CoNLL-X shared task on word alignment #REFR."}
{"labels": "Many previous works show promising results with an assumption that syntactic cohesion explains almost all translation movement for some language pairs #OTHEREFR; #REFR.", "predict": "A number of recent works have addressed the task of automatic sentiment classification, including #OTHEREFR; #REFR, #OTHEREFR."}
{"labels": "The pyramid method #REFR, was inspired in part by work in reading comprehension that scores content using human annotation #OTHEREFR.", "predict": "The best results are achieved with the following parameters:?0.01,?0.01,?0.01,?0.01,?0.01,?0.01,?0.01,?0"}
{"labels": "Correcting POS annotation errors can be done by applying a POS tagger and altering the input POS tags #REFR.", "predict": "For this purpose, we use the Stanford Parser #REFR."}
{"labels": "The Opinosis dataset #REFR consists of short user reviews in 51 different topics.", "predict": "In the same work #REFR, the word-to-word similarity is used to predict the probability of a word being a verb."}
{"labels": "Future research will investigate more sophisticated methods of text-to-text similarity for prompt-based content scoring, such as those used in #REFR.", "predict": "We evaluate our method on the task of identifying the most frequent words in a document #REFR."}
{"labels": "We pre-process the dataset with the following tools: the Charniak Parser #REFR for parsing sentences, the WordNet similarity package #OTHEREFR for creating the SYNT and the FOR feature spaces.", "predict": "In the next section, we present the results of the experiments on the German-English corpus #OTHEREFR; #REFR."}
{"labels": "False Opinion Targets: In another case, the phrase?wonderful time? can be matched by an opinion pattern?Adj-{mod}-Noun?, which is widely used in previous works #REFR.", "predict": "For instance, #REFR used an HMM model to learn the distribution of words in a corpus."}
{"labels": "#REFR investigate questions of dialectal differences and variation in regional interests in Twitter users using a collection of geotagged tweets.", "predict": "2The?85511? and?85520? in the English corpus were obtained by using the Stanford parser #REFR."}
{"labels": "In addition, we have thrown further doubt on the possible use of the PTB for cross-framework parser evaluation, as recently suggested by #REFR.", "predict": "In the context of machine translation, the most common approach is to use a translation model #OTHEREFR; #REFR."}
{"labels": "The use of prosodic and coarticulatory context has improved the effectiveness of tone and pitch accent recognition in a range of languages #OTHEREFR, and CRFs #REFR).", "predict": "#REFR used a word-based approach to generate a list of possible translation candidates for a given sentence."}
{"labels": "#REFR investigated system combination using automatic generation of diverse individual systems.", "predict": "We use the system of #REFR, which is a standard system that uses a single phrase-based SMT system and a treebank based phrase-based SMT system."}
{"labels": "Therefore, the feature model focuses on each kind of head-child pair in the dependency tree, and mainly contains four categories of features #REFRa): basic uni-gram features, basic bi-gram features, in-between POS features, and surrounding POS features.", "predict": "In particular, we apply the method described in #REFR to the data in the CoNLL-2007 shared task."}
{"labels": "Nearly all previous work on unsupervised grammar induction has focused on learning hierarchical phrase structure #OTHEREFR; #REFR or dependency structure #OTHEREFR.", "predict": "This paper reports the results of the coreference resolution task on the English data from the CoNLL shared task on coreference resolution #REFR."}
{"labels": "Another common type of projection methods map labels from resource-rich language sentences to resource-scarce ones in a parallel corpus using word alignment information #REFR.", "predict": "The work by #REFR is one of the most recent and significant contributions to the problem of detecting and detecting word errors."}
{"labels": "Our interpretation is more useful than past interpretations involving marginal constraints #OTHEREFR or maximum-entropy models #REFR as it can recover the exact formulation of interpolated Kneser-Ney, and actually produces superior results. #OTHEREFR has independently noted the correspondence between the hierarchical Pitman-Yor", "predict": "The algorithm we used is a simple and effective algorithm for extracting word sense disambiguation (WSD) information from text #REFR."}
{"labels": "PARC 700 Dependency Bank following #REFR The results are given in Table 7.", "predict": "#REFRb) used the same approach to detect the word sense in English and Japanese."}
{"labels": "Although statistical approaches to automatic term recognition, e.g. #OTHEREFR; #REFR, have achieved relative success over the years, the addition of suitable linguistic information has the potential to enhance results still further, particularly in the case of small corpora or very specialised omains, where statistical information may", "predict": "We are using the HMM based method described in #REFR."}
{"labels": "It has received significant attention in recent years due to increasing online opinion content and applications in tasks such as automatic product recommendation systems #OTHEREFR and opinions #REFRa).", "predict": "Our model is a variation of the phrase-based SMT model of #REFR."}
{"labels": "Results of this evaluation and comparisons with our theoretical figures are further described in #REFR.", "predict": "We used the Stanford tagger #REFR for word segmentation, the Stanford Parser #OTHEREFR for word sense disambiguation."}
{"labels": "Alignments were learned using two iterations of Model 1 and two iterations of the HMM alignment model #REFR.", "predict": "This is a general problem that has been addressed by several approaches, such as #REFR and #OTHEREFR."}
{"labels": "#REFR use machine translation for multilingual sentiment analysis.", "predict": "This is an important observation because #REFR show that the quality of a word alignment can greatly affect the performance of a machine translation system."}
{"labels": "Here we report first quantitative results on the ATIS3 corpus #REFR.", "predict": "1996) and a word sense disambiguation system for Japanese #REFR."}
{"labels": "For example, citation-based summarization systems #REFR and survey generation systems #OTHEREFR can benefit from citation purpose and polarity analysis to improve paper and content selection.", "predict": "We use the 1300-word test set of the CoNLL-X 2007 shared task on dependency parsing #REFR."}
{"labels": "We use MXPOST tagger #OTHEREFR for POS tagging, Charniak parser #REFR for extracting syntactic relations, SVMlight1 for SVM classifier and David Blei?s version of LDA2 for LDA training and inference.", "predict": "The method is based on the idea that the word pair in a sentence can be estimated as a feature for a word-to-word translation model #REFR."}
{"labels": "Thanks to this sort of activation flow FIG tends to select and emit an appropriate word in an appropriate form #REFR.", "predict": "The task is to predict the relation between the two sentences #OTHEREFR; #REFR."}
{"labels": "The deterministic shift/reduce classifier-based dependency parsing approach #REFR has been shown to offer state-of-the-art accuracy #OTHEREFR with high efficiency due to a greedy search strategy.", "predict": "In addition, the use of multiple sources of data #OTHEREFR; #REFR can improve performance."}
{"labels": "This method is more similar to the one used in #REFR, with the difference that they use only 1-best input from a base MT system.", "predict": "A more detailed description of this system is given in #REFR."}
{"labels": "#REFR used a Roget-like thesaurus, co-occurrence statistics, and a seed set of antonyms to identify the degree of antonymy between two words, and generate a list of antonymous words.", "predict": "The main idea is to reduce the problem of sentence compression to a single problem of word compression, which is well-studied #OTHEREFR; #REFR."}
{"labels": "The English corpus contains 47613 sentences, that were POS tagged using Stepp Tagger #OTHEREFR, and use the Lemmatizer #REFR to extract and stem content words (nouns, verbs, adjectives, adverbs).", "predict": "The most widely used model for this task is the one described in #REFR."}
{"labels": "#REFR introduced a corpus-based approach for generating a K?K matrix for each verb from an average of Kronecker products of the subject and object vectors from the positively labelled subset of the training data.", "predict": "For instance, #REFR proposed to use the word alignment between a source and a target language as a tool for improving the translation quality."}
{"labels": "Gi#REFR reports a relation discovery algorithm based on Hearst.", "predict": "The best system #REFR is a 3-gram language model with a language model based on the co-occurrence statistics of the words in a training corpus."}
{"labels": "Our error analysis above also highlights our task?s difference with previous work that identify corresponding phrases between two sentences, including phrase extraction #REFR and paraphrase extraction #OTHEREFR.", "predict": "We have also performed experiments using the 120,000 English sentences of the CoNLL 2009 shared task #REFR."}
{"labels": "To address this problem, there have been several recent attempts to incorporate into distributional semantic models a component that generates vectors for unseen linguistic structures by compositional operations in the vector space #REFR.", "predict": "We compare our approach to the state-of-the-art algorithm of #REFR, which uses the same set of features, and show that our approach is better."}
{"labels": "Several approaches have modified the Lesk algorithm to reduce is exponential complexity, like the one based on Simulated Annealing #REFR.", "predict": "This task has been studied extensively #OTHEREFR; #REFR."}
{"labels": "In recent years a variety of statistical models for realization ranking that take syntax into account have been proposed, including generative models #OTHEREFR; #REFR, maximum entropy models #OTHEREFR.", "predict": "The task of automatic phrase-based translation #REFR has also been addressed by other work."}
{"labels": "We have been building the Sandglass MT system for the Japanese-Chinese, Chinese- Japanese language pairs #OTHEREFR; #REFR.", "predict": "A detailed description of the system is given in #REFR."}
{"labels": "There are two kinds of methods for morphological disambiguation: onone hand, statistical methods need little effort and obtain very good results #OTHEREFR; #REFR, at least when applied to English, but when we try to apply them to Basque we encounter additional problems; on the other hand, some rule", "predict": "The most common approach to this problem is to use the same set of features as #REFR."}
{"labels": "Methodologies such as lexicalisation #OTHEREFR; #REFR and tree transformations #OTHEREFR, weaken the independence assumptions and have been applied successfully to parsing and shown significant improvements over simple PCFGs.", "predict": "In particular, we will evaluate the performance of the models in two different tasks: the first is the automatic evaluation of a word sense disambiguation system, and the second is the automatic evaluation of the performance of a phrase-based machine translation system #REFR."}
{"labels": "#REFR suggested a division of countability into five major types, based on Allan #OTHEREFR?s noun countability preferences (NCPs).", "predict": "Phrase-based models have been successfully applied to several natural language processing tasks #OTHEREFR; #REFR."}
{"labels": "In this section we introduce basic definitions related to synchronous context-free grammars and their probabilistic extension; our notation follows #REFR.", "predict": "The language model is trained with the Stanford Parser #REFR."}
{"labels": "In principle, the comparison can be done via coselection of extracted sentences #OTHEREFR; #REFR, by string-based surface measures #OTHEREFR.", "predict": "#REFR presents a method for selecting the best translation from a corpus of sentences."}
{"labels": "An investigation propose that boundary strength according to the measure, which the boundary strength is applied to syntactic structures and the phrase structure is viewed as an immediate constituency tree exclusively, corresponds much more closely to empirical prosodic boundary strength than does syntactic boundary strength according to a standard measure #REFR.", "predict": "To make the work more accessible to researchers who are not familiar with the methods in #REFR, we provide a detailed description of our system."}
{"labels": "Several methods have been proposed with regard to aligning sentences #OTHEREFR; #REFR.", "predict": "This is also consistent with the results reported in #REFR, where the results for the English and French datasets are similar."}
{"labels": "#REFR\\] propose a large scale method, but results are reported for only one sentence, and no success rate is given.", "predict": "The work in #REFR, in particular, shows that a large number of words can be used to represent the semantic role of a word in a context."}
{"labels": "There are also automatic measures which do not require model summaries, but compare against the source text instead #OTHEREFR; #REFR.", "predict": "In this paper, we present the first application of the approach in the context of an automatic evaluation of the translation quality of English to Chinese #REFR."}
{"labels": "At first, additional linguistic resources, such as specialized dictionaries #REFR or transliterated words #OTHEREFR, were combined with the seed dictionary to translate context vectors.", "predict": "We used the same data set as #REFR, but with a different feature set."}
{"labels": "We choose to use an earlier neural network based probabilistic model of parsing #REFR, whose hidden units can be viewed as approximations to latent variables.", "predict": "The algorithm is similar to that described in #REFR."}
{"labels": "In #REFR we proposed a general protocol for handling annotation discrepancies when comparing parses across different dependency theories.", "predict": "#REFR propose an algorithm to learn a set of non-parallel sentences, based on the sentence alignments obtained by a set of non-parallel alignments of the same domain."}
{"labels": "For instance, measures that compute the association strength between the elements of an expression have been employed to determine its degree of compositionality #OTHEREFR (see also #REFR for an overview and a comparison of different measures).", "predict": "In particular, the approach of #REFR, which we follow, provides a strong foundation for the analysis of lexical semantic roles, which are a fundamental component of language understanding."}
{"labels": "In #REFR, it is proposed a matrix-vector recursive neural network model for semantic compositionality, which has the ability to learn compositional vector representations for phrases and sentences of arbitrary length.", "predict": "The approach we take is closely related to the approach of #REFR, who apply the HMM to the word alignment problem."}
{"labels": "This problem is a counterpart to the image description problem #OTHEREFR; #REFR, which has so far remained largely unexplored by the community.", "predict": "In order to solve this problem, several approaches have been proposed, including the use of feature-based methods #OTHEREFR; #REFR."}
{"labels": "Unlabeled data has been shown to improve the accuracy of conjunctions within complex noun phrases #REFR.", "predict": "The most common approach to this problem is to learn a model from a large corpus #OTHEREFR; #REFR."}
{"labels": "The method has also been popular in the related task of noun clustering #REFR.", "predict": "The results in Table 1 also show that the best system #REFR, which was trained on the test set, does not improve over our system on the test set."}
{"labels": "Care was taken to ensure not just that the utterances themselves, but also the speakers of the utterances were disjoint between test and training data; as pointed out in #REFRa), failure to observe these precautions can result in substantial spurious improvements in test data results.", "predict": "We also use a standard treebank-based translation model #REFR."}
{"labels": "Previous work on transfer-based MT systems #REFR and alignment-based transfer knowledge acquisition #OTHEREFR have proven that transfer knowledge can be best represented by declarative structure mapping (transforming) rules each of which typically consists of a pair of source and target partial structures as in the middle of Figure", "predict": "We use the 13000 words of the 2003 American English Word Sense Disambiguation corpus #REFR."}
{"labels": "To speed up Viterbi parsing, sophisticated search strategies have been developed which find the most probable analysis without examining the whole set of possible analyses #OTHEREFR; #REFRa).", "predict": "For the task of sentence compression, #REFR proposed an unsupervised method that uses a word-level word sense disambiguation algorithm to learn the sense of each word."}
{"labels": "Historically MT researchers have focused their attention on the mismatch of linear realization of syntactic arguments #OTHEREFR and word polysemy #REFR.", "predict": "Our experiments are based on the data provided by #REFR."}
{"labels": "Researchers have explored error detection for manually tagged corpora in the context of pos-tagging #REFR, dependency parsing #OTHEREFR.", "predict": "For this reason, a variety of algorithms have been proposed, including #OTHEREFR; #REFR."}
{"labels": "Although the overall parsing style of our system integrates template-based and language-based strategies \\[#REFR\\], the skimming algorithm is actually more bottom-up or language-based.", "predict": "In this paper, we use the MERT algorithm #REFR to evaluate the performance of our method."}
{"labels": "Several unsupervised POS induction systems make use of morphological features #OTHEREFR; #REFR and this approach has been empirically proved to be helpful #OTHEREFR.", "predict": "#REFR present an unsupervised method for learning the semantic structure of a sentence."}
{"labels": "Our data sources are the German NeGra #REFR and TIGER #OTHEREFR treebanks.", "predict": "This task is also related to the task of automatic annotation of lexical relations #REFR."}
{"labels": "We show that by augmenting the delexicalized direct transfer system of #REFR with cross-lingual cluster features, we are able to reduce its error by up to 13% relative.", "predict": "A number of research studies have been conducted on the problem of identifying and analyzing the opinions of the people in a given domain #OTHEREFR; #REFR."}
{"labels": "Subsequent work explored ways of exploiting linguistically annotated data for trainable generation models #REFR; Marciniak and Strube, 2005; Belz, 2005, a.o.).", "predict": "In the past few years, there has been a significant amount of research on the topic of semantic role labeling #OTHEREFR; #REFR."}
{"labels": "The speed and cost benefits for annotation are certainly impressive #OTHEREFR; #REFR but we hope to show that some of the greatest gains are in the very nature of the phenomena that we can now study.", "predict": "The algorithm has been used for a variety of NLP tasks, including syntactic parsing #OTHEREFR; #REFR, semantic role labeling #OTHEREFR."}
{"labels": "Related sentences are represented by a word graph so that summaries constitute paths in the graph #REFR.", "predict": "For the same reasons, we use a model based on the same type of tree-to-string translation models #REFR."}
{"labels": "Most of the research as focused on bilingual terminology identification, either as parallel multiwords forms #OTHEREFR), technical terminology (e.g. the Termight system #REFR or broad-coverage translation lexicons #OTHEREFR).", "predict": "Our approach is based on the work of #REFR, who used a similar approach to identify the most frequent words in the text and use these words to improve the accuracy of a tagger."}
{"labels": "The domaingeneral DM was mostly abstracted from the TALK system #REFR.", "predict": "In this paper, we present a simple and effective method for using the resources of a human expert for the prediction of word sense in English #REFR."}
{"labels": "This is partly due to its relevance for applications ranging from information extraction #OTHEREFR, and the modeling of textual entailment relations #REFR.", "predict": "The second approach, as described in #REFR, is to use the same distributional properties in the training and testing sets, which means that all training data can be used to improve the performance of the system."}
{"labels": "Bilingual word alignments are trained and combined from two sources: GIZA #REFR and maximum entropy word aligner #OTHEREFR.", "predict": "To build the word alignments, we use the Stanford Parser #REFR."}
{"labels": "Thanks to specific reordering modeling components, phrase-based SMT #OTHEREFR; #REFR are generally good at handling local reordering phenomena that are not captured inside phrases.", "predict": "2.1.1 Syntax-based approaches We have also used the model proposed by #REFR."}
{"labels": "These rules can be handcrafted grammar rules, such as those of #OTHEREFR or, alternatively, extracted fully automatically from treebanks #REFR.", "predict": "This is a method of learning a semantic parser from data in the form of sentence pairs #REFR."}
{"labels": "Over the years, several approaches for mining translations from non-parallel corpora have emerged #OTHEREFR; #REFR, all sharing the same Firthian assumption, often called the distributionial hypothesis #OTHEREFR, which states that words with a similar meaning are likely to appear in similar contexts across languages", "predict": "#REFR use an HMM to predict the position of a word in a sentence."}
{"labels": "Many computational models of compositionality focus on learning vector spaces #OTHEREFR; #REFR.", "predict": "The idea of using multiple languages to improve the performance of a machine translation system has been proposed in several studies #OTHEREFR; #REFR."}
{"labels": "This is the approach taken by #REFR, where they estimate what in our terms are projections of the raw treebank grammar from the treebank itself.", "predict": "#REFR also proposed a machine learning-based system to detect the semantic relation between two words."}
{"labels": "Transliteration methods typically fall into two categories: generative approaches #OTHEREFR; #REFRa), that try to identify the correct transliteration for a word in the source language given several candidates in the target language.", "predict": "This is a standard approach in statistical machine translation #REFR."}
{"labels": "These results are astonishing considering that #REFR ignored candidates that appeared less than 10 times (because they were unreliable). nouns because their morphological behaviors were the same as those of nouns.", "predict": "In the future, we will extend our method to include the use of lexical information, e.g., in the form of lexical features or semantic roles #OTHEREFR; #REFR."}
{"labels": "Amazon Mechanical Turk is a crowdsourcing platform that has been extensively used for obtaining low-cost human annotations for various linguistic tasks over the last few years #REFR.", "predict": "This is an extension of the model described by #REFR."}
{"labels": "Recently, #REFR have reported experiments on learning information structure in the Prague TreeBank.", "predict": "The model we use is the one proposed by #REFR."}
{"labels": "#REFR employ a semi-automatic method to improve a large-scale morphosyntactic lexicon of French #OTHEREFR).", "predict": "We use the Stanford Parser #REFR to parse the text and build a parse tree."}
{"labels": "There have been a number of recent studies on probabilistic treebank parsing of German #OTHEREFR, using the Negra treebank #REFR as their underlying data source.", "predict": "In this paper, we use a set of features developed for this task #REFR."}
{"labels": "Finally, we have also considered ULC, which is a very simple approach to metric combination based on the unnormalized arithmetic mean of metric scores, as described by Gime?nez and Ma`#REFRa).", "predict": "In this paper we report on the results of our previous work #REFR on an English-Spanish corpus."}
{"labels": "This weight vector is learned using a simple Perceptron like algorithm similar to the one used in #REFR.", "predict": "We used the Stanford Parser #REFR to generate the?X?-based parse trees."}
{"labels": "They are characterized by the following properties #REFRb):", "predict": "This is similar to the method used in #REFR."}
{"labels": "Work on preposition errors has used a similar classification approach and mainly differs in terms of the features employed #OTHEREFR; #REFR.", "predict": "In the context of machine translation, #REFR proposed a technique to extract the best translation from the training data."}
{"labels": "Parallel sentences were first word-aligned using a MaxEnt aligner #REFR.", "predict": "In this paper we extend the approach of #REFR, which uses the same set of features, and apply the same feature selection method to the problem of identifying the most frequent phrase pair."}
{"labels": "Identification of semantically similar situations can be improved by the use of segmentmatching algorithms as employed in Example- Based MT and translation memories #REFR.", "predict": "The model is similar to the model of #REFR."}
{"labels": "Others have exploited the automatic transfer of some already existing annotated resource in a different medium or language (such as the translingual projection of part-of-speech tags, syntactic bracketing and inflectional morphology in #REFR, requiring no direct supervision in the foreign language).", "predict": "For example, #REFR used the following two types of features:? features that allow a word to be recognized as an?N-gram?, where N is the number of characters in the word;? features that allow a word to be recognized as a word."}
{"labels": "Recent work has shown how paraphrases can improve question answering through query expansion #OTHEREFR, automatic evaluation of translation and summarization by modeling alternative lexicalization #REFR, and machine translation both by dealing with out of vocabulary words and phrases #OTHEREFR.", "predict": "#REFR proposed an approach to extract sentence-level semantic information from text."}
{"labels": "Currently, the performance of even the most simple direct transfer systems far exceeds that of unsupervised systems #OTHEREFR; #REFR.", "predict": "#REFR show that the same model of the word pair can be used to learn a language model that can be used to produce both the sentence and the phrase in a single model."}
{"labels": "For our Chinese to English translation experiments, we generated word alignments using the Berkeley Aligner #REFR with default settings.", "predict": "The main approach for evaluating the quality of language models is to evaluate the performance of the model in a production-level setting, e.g., in NLP tasks such as word sense disambiguation #OTHEREFR, or in a testing set of data #REFR."}
{"labels": "ORIG with fixed hyperparameters performs best, with the highest VM score (a clustering measure, #REFR) and a level of segmentation close to the correct one.", "predict": "In this paper, we propose a new method for automatic parsing based on the model of #REFR."}
{"labels": "Conditional random fields #OTHEREFR are quite effective at sequence labeling tasks like shallow parsing #REFR and namedentity extraction #OTHEREFR.", "predict": "1The results are similar to those obtained by #REFR."}
{"labels": "State-of-art approaches to frame-based SRL are based on Support Vector Machines, trained over linear models of syntactic features, e.g. #REFRb), or tree-kernels, e.g. #OTHEREFR.", "predict": "We use the HMM-based system of #REFR."}
{"labels": "This would also include more semantic information, e.g., in the form of Brown clusters or using semantic similarity between the words composing the structure calculated with latent semantic analysis #REFRb).", "predict": "The most popular approach to sentiment analysis #REFR is to use a set of words that describe the sentiment of a document."}
{"labels": "Following #REFR, we use the default parameters (? = 0.1 and?0 = 1.0) for HDP.1 For each target word, we apply HDP to induce the senses, and a distribution of senses is produced for each?document? in the model", "predict": "The first,?new?, is an unlexicalized SMT model with a single feature for each word in the corpus, following #REFR."}
{"labels": "Some of these needs can be addressed by emerging technologies for temporal analysis #OTHEREFR; #REFR.", "predict": "#REFR introduced the concept of syntactic parse trees, which are the trees built from the parse trees of a given sentence."}
{"labels": "Our work joins others in using continuous representations to express the meaning of words and phrases #REFR and how these may be combined in a language modeling context #OTHEREFR.", "predict": "The most common approach is to use a statistical language model #REFR."}
{"labels": "5The meaning of the word \"synchronized\" here is exactly the same as in STAG #REFR.", "predict": "The idea of automatic extraction of semantic categories has been studied for several decades #OTHEREFR; #REFR."}
{"labels": "A Data-Oriented Parsing model #OTHEREFR; #REFR, 1993a) is characterized by a corpus of analyzed language utterances, together with a set of operations that combine sub-analyses from the corpus into new analyses.", "predict": "#REFR show that the use of syntactic features is important for the accuracy of the system."}
{"labels": "Transition-based dependency parsing can be modeled under this framework, where the state consists of a stack and a queue, and the set of actions can be either the arc-eager #REFR or the arc-standard #OTHEREFR transition systems.", "predict": "We also plan to compare with the existing state-of-the-art systems #REFR and to test our system on the same data."}
{"labels": "Phrase-based SMT models, such as the alignment template model #REFR, improve on word-based models because phrases provide local context which leads to better lexical choice and more reliable local reordering.", "predict": "We use the Stanford Parser #REFR to extract lexical information from the Penn Treebank, and then apply a set of statistical techniques to determine the syntactic structure of the sentences."}
{"labels": "Similar work has also been performed in the area of query expansion using training data consisting of FAQ pages #OTHEREFR or queries and clicked snippets from query logs #REFR.", "predict": "We use the Stanford Parser #REFR to parse the English part of the text."}
{"labels": "Many approaches have been devised, including the identification of domain-specific predominant senses #OTHEREFR; #REFR, the development of domain resources #OTHEREFR.", "predict": "This approach is similar to the one used by #REFR."}
{"labels": "#REFR described a WSD method and an implementation based on Roget' s Thesaurus and the training material of the 10-rnillion-word Grolier' s Encyclopedia.", "predict": "In addition to the best-performing system in the CoNLL shared task #REFR, we have found that our system is also the best performing system on the CoNLL-2012 data."}
{"labels": "Deep and accurate text analysis based on discriminative models is not yet efficient enough as a component of real-time applications, and it is inadequate to process Web-scale corpora for knowledge acquisition #OTHEREFR or semi-supervised learning #REFR.", "predict": "We use the Stanford POS tagger #REFR to extract POS tags for the target sentence."}
{"labels": "We have extended non-projective unlabeled dependency parsing #REFR to a very simple non-projective labeled dependency and showed that the parser performs reasonably well with small number of features and just one iteration of training.", "predict": "In this paper, we extend the method described in #REFR, and present the results of our experiments on a single language, English."}
{"labels": "There has been much recent work in attempting to convert native parser output into alternative representations for evaluation purposes, e.g. #OTHEREFR; #REFR.", "predict": "The results in #REFR and #OTHEREFR show that this approach is successful in the context of word segmentation and sentence segmentation."}
{"labels": "Recently, #REFR has reported a word accuracy of 92.6% for Dutch, using a `lazy' training strategy on data aligned with the correct phoneme string, and a hand-crafted system that relied on a large set of rule templates and a many-to-one mapping of characters", "predict": "#REFR used a combination of syntactic and semantic features to identify the meaning of words."}
{"labels": "Previous research has shown that RST trees can play a crucial role in building natural language generation systems #OTHEREFR and text summarization systems #REFR; can be used to increase the naturalness of machine translation outputs #OTHEREFR.", "predict": "The second part of the task is to obtain a high quality parser from the source data #REFR."}
{"labels": "These same features also proved crucial to subsequent approaches, e.g. #REFR.", "predict": "In addition to the phrase-based approach of #REFR, the language model approach of #OTHEREFR has also been applied to phrase-based SMT."}
{"labels": "For this reason, we compute an unweighted entity-constrained mention F-measure #REFR and report all contrastive experiments with this metric.", "predict": "For instance, #REFR, #OTHEREFR."}
{"labels": "After the error miner identifies afwater as a problematic word, we employ our machine learning based LA method presented in #REFR to learn new entries for this word.", "predict": "The algorithm is a combination of the two best-performing approaches, the one of #REFR and the one of Li and Hovy #OTHEREFR."}
{"labels": "To further assure the quality of the annotation, a series of automatic tests was performed and used as the basis of a further manual round of revision.4 Annotation guidelines were initially created based on those created by our previous domain-specific effort #REFRa) and revised throughout the annotation effort to document specific decisions made", "predict": "We use the standard 1-best F1 score #REFR."}
{"labels": "These User Simulations are now commonly used in statistical learning approaches to dialogue management #OTHEREFR; #REFR, but they have not been used for context-sensitive ASR before.", "predict": "The best performance for the?c?-style model was achieved in the C&C-79 task #REFR."}
{"labels": "Other work has shown that co-occurrence of words #OTHEREFR and discourse relations #REFR also predict coherence.", "predict": "The model has been shown to be very effective for a variety of NLP tasks, including word sense disambiguation #OTHEREFR; #REFR, and text summarization #OTHEREFR."}
{"labels": "It is a well-documented fact #REFR that subcategorisation frames (and their frequencies) vary across domains.", "predict": "#REFR present an approach to this problem."}
{"labels": "In this paper we focus on recurrent neural network architectures, which have recently advanced the state of the art in language modeling #OTHEREFR; #REFR, outperforming multi-layer feed-forward based networks in both perplexity and word error rate in speech recognition #OTHEREFR.", "predict": "The model is based on the HMM-based dependency parser of #REFR."}
{"labels": "As our approach for incorporating unlabeled data, we basically follow the idea proposed in #REFR.", "predict": "In addition, there are two different types of models: tree-to-string models #OTHEREFR; #REFR and tree-to-string models #OTHEREFR."}
{"labels": "We extended the unsupervised corpus-extracted phrase approximation method of Guevara #OTHEREFR and #REFR to estimate all known state-of-the-art cDSMs, using closedform solutions or simple iterative procedures in all cases.", "predict": "To evaluate the performance of the system, we used a set of test sets that was obtained by using the 100000 test sentences from the Penn Treebank #REFR."}
{"labels": "The paradigm of translation for monolinguals introduced by Kay in 1973 #OTHEREFR; #REFR).", "predict": "1The results are compared to the state-of-the-art methods described in #REFR."}
{"labels": "The projected trees can be used to answer linguistic questions such as word order #REFR or bootstrap parsers #OTHEREFR.", "predict": "In the context of the NLP community, this has led to the development of new methods for the extraction of syntactic information #OTHEREFR; #REFR."}
{"labels": "We evaluated our system using the standard evaluation script provided by the organizers #REFR.", "predict": "This has led to the development of a number of statistical machine translation systems #OTHEREFR; #REFR."}
{"labels": "Second, we prune the phrase-table using a statistical significance test to measure #REFR.", "predict": "The use of a maximum entropy model for word alignment has been shown to improve performance for a variety of NLP tasks #REFR."}
{"labels": "To this end, patternbased approaches have long been used to induce type systems #REFR.", "predict": "We use the same training and testing sets as #REFR."}
{"labels": "They include such topics as: work with various corpus manipulation and annotation tools, use of various POS taggers and their comparison #REFR, development of morphophonological rules in PC-Kimmo #OTHEREFR.", "predict": "The work of #REFR is an interesting extension of this idea, in which the word-based approach is used in a language model-based approach."}
{"labels": "First, even when sentiment is the desired focus, researchers in sentiment analysis have shown that a two-stage approach is often beneficial, in which subjective instances are distinguished from objective ones, and then the subjective instances are further classified according to polarity #OTHEREFR; #REFR.", "predict": "For example, the use of word sense disambiguation to identify the appropriate translation of words in English #REFR is a well-known approach."}
{"labels": "Compared to graph-based dependency parsing, it typically offers linear time complexity and the comparative freedom to define non-local features, as exemplified by the comparison between MaltParser and MSTParser #OTHEREFR; #REFR.", "predict": "The first one is the use of a tree-to-string translation model #REFR, which is a language model that takes the input as a tree, and produces a string of words."}
{"labels": "Unbalanced corpora are common in a number of different tasks, such as emotion detection #OTHEREFR; #REFR, text classification #OTHEREFR, and so on1.", "predict": "A more detailed description of the system is given in #REFR."}
{"labels": "Metrics in the Rouge family allow for skip n-grams #OTHEREFRa); #REFR take paraphrasing into account; metrics such as METEOR #OTHEREFR in that word class information is used.", "predict": "#REFR."}
{"labels": "Therefore, recent efforts #REFR have concentrated on feature design? wherein more intelligent features may be added.", "predict": "#REFR propose a maximum entropy-based algorithm for generating semantic relations."}
{"labels": "#REFR report better results than ours on Portuguese, Slovene, Spanish and Swedish, but worse on Danish.", "predict": "The best-performing system for English has been described in #REFR."}
{"labels": "We used three aligners in this work: GIZA++ #OTHEREFR, jointly trained HMM #REFR, and ITG #OTHEREFR.", "predict": "The first is a standard SMT system that uses a 5-gram language model #REFR to generate word alignments for both language pairs."}
{"labels": "#REFR propose a solution to this problem: for each token, they define additional features based on known information, taken from other occurrences of the same token in the document.", "predict": "We compare our system to the state-of-the-art in a task that has received increasing attention over the last few years: word sense disambiguation #OTHEREFR; #REFR."}
{"labels": "Among the current similar works, Table 4 shows that our system outperforms Chen#OTHEREFR in VV compounds, and approximates the #REFR in NN compounds.", "predict": "For example, #REFR use a?word-level? method to combine features based on the word frequency."}
{"labels": "A similar modification was used by #REFR for the study of dependency parsing models.", "predict": "Our work is closely related to the work of #REFR."}
{"labels": "In both cases, transfer is driven by the transfer module developed and implemented by #REFRa).", "predict": "The algorithm was first proposed in #REFR."}
{"labels": "Such text data tend to be long and generate enough context for the target task #OTHEREFR; #REFR.", "predict": "This is in contrast to previous work that used a linear model for the analysis of sentences #OTHEREFR; #REFR."}
{"labels": "In a related recent approach, #REFR presented preliminary results from automatically generating related work sections for a target paper by taking a hierarchical topic tree as an input; however, the requirement of a pre-conceived topic tree limits the scalability of this system.", "predict": "#REFRb) proposed a framework to extract word-level features from parallel corpora."}
{"labels": "Although it has been shown that increasing the amount of training data for SMT improves results #REFR, not all data is beneficial, and clean data is best of all.", "predict": "In recent years, several statistical machine translation (SMT) approaches have been developed for natural language processing tasks such as information retrieval #OTHEREFR; #REFR, summarization #OTHEREFR."}
{"labels": "We first extracted named entities using a Twitter-tuned NER system #REFR from millions of tweets, which we collected over a one-year period spanning from January 2012 to January 2013; we used the public streaming Twitter API to download tweets.", "predict": "The?c2k? system uses a 5-gram language model and a 3-gram language model #REFR."}
{"labels": "Past studies of combining alternative alignments focused on minimizing alignment errors, usually by merging alternative alignments for a sentence pair into a single alignment with the fewest number of incorrect alignment links #REFR.", "predict": "In the same way as #REFR, we use the 125 words of the training corpus to define the set of words to be translated."}
{"labels": "#REFR presented a statistical system that automatically produces an analysis of the rhetorical structure that holds between sets of sentences or clauses at the paragraph level.", "predict": "We use the same?SVM? model described in #REFR, which is a multi-class classification model."}
{"labels": "We employ the features of noun terms, and sentiment terms in the sentiment lexicon provided by MPQA project #REFR.", "predict": "This is similar to the approach used in #REFR for annotating a text with its semantic similarity with a large corpus of text."}
{"labels": "A translation model consists of two distinct elements: an unweighted ruleset, and a parameterization #REFR.", "predict": "5This result is also consistent with #REFR."}
{"labels": "We are inspired by multiple sequence alignment methods in computational biology #OTHEREFR and by #REFR, who described a hidden Markov model (HMM) for document content where each state corresponds to a distinct topic and generates sentences relevant to that topic according to a language model.", "predict": "To evaluate the performance of our approach, we used the 200000 words in the CoNLL-X shared task on dependency parsing #REFR."}
{"labels": "Unlike other languages #REFR, Chinese UNK translation cannot use information from stem and inflection analysis.", "predict": "This paper presents an implementation of the algorithm of #REFR to find the best translation."}
{"labels": "For this paper, we consider tree-shaped hierarchies so that tree kernels, e.g. #OTHEREFR; #REFRa), can be applied.", "predict": "This is similar to the approach taken by #REFR, who applied a statistical approach to detect relations between entities."}
{"labels": "We follow the same approach as in #REFR to build our SWSD system.", "predict": "This is a very important issue, and many approaches have been proposed for this purpose, such as #OTHEREFR; #REFR."}
{"labels": "The dataset is the same as in leading works #REFR.", "predict": "#REFR and De Niro and Ziffen #OTHEREFR)."}
{"labels": "Part of the work using this tool was described by #REFR.", "predict": "We used the Stanford parser #REFR to parse the sentences and extract word alignments."}
{"labels": "However, the performance of context vectors drastically decreases for lower frequency terms #REFR.", "predict": "This task has been considered in the literature, but has not been addressed directly for English.1 In the context of machine translation, it has been suggested to use a disambiguation task to ensure that translation rules are correct #REFR."}
{"labels": "#REFR explored strategies for selecting better random?restart points? in optimization.", "predict": "We are not aware of any previous work on this task. #REFR describes a method for detecting the presence of word-level dependencies between words in a sentence."}
{"labels": "The Grammar Matrix customization system #REFR presents the linguist-user with a typological questionnaire which elicits information about the language to be described.", "predict": "For instance, #REFR apply an algorithm to extract the words of a document, which can be used to build a grammar."}
{"labels": "The model is called Transfer- Driven Machine Translation (TDMT) #REFR (see subsection 2.1 for details).", "predict": "This is the same approach as that used by #REFR, which is also known as?word sense disambiguation?."}
{"labels": "These modifications, however, give a system which suffers 2See, for example, the formalisms developed in #OTHEREFR, #REFR. the problem of woulderivational equivalence', also called ispurious ambiguity', i.e. allowing multiple proofs which assign the same reading for", "predict": "This is in line with the approach of #REFR, who use the same data as ours."}
{"labels": "On the other hand, #REFR proposed a resolving algorithm for Japanese exophoric ellipses of written texts, utilizing semantic and pragmatic onstraints.", "predict": "The approach of #REFR is based on a statistical method for extracting a set of words that are similar in meaning."}
{"labels": "Cutting introduced grouping of words into equiva.lence classes based on the set of possible tags to reduce the number of the parameters #REFR.", "predict": "For the SMT system we used the same training and evaluation data as #REFR."}
{"labels": "#REFR proposed several approaches for cross lingual subjectivity analysis by directly applying the translations of opinion corpus in source language to train the opinion classifier on target language.", "predict": "This is a similar approach to the one used in #REFR."}
{"labels": "#REFR evaluate various similarity measures based on 1000 frequent and 1000 infrequent target terms.", "predict": "The same idea was used in the work of #REFR, where the goal was to find the most frequent phrase in a sentence."}
{"labels": "This was the setting obtaining the best results in a word similarity dataset as reported by #REFRb).", "predict": "This approach is different from the approach of #REFR, who proposed a system to detect the sense of a word in the target language."}
{"labels": "In the last 4-5 years, researchers have begun to introduce compositional operations on distributional semantic representations, for instance to combine verbs with their arguments or adjectives with nouns #OTHEREFR; #REFR1.", "predict": "In particular, we present a method to identify the number of features for a sentence in a document, and also identify the number of features for a document in a document #REFR."}
{"labels": "MERT is the standard technique for obtaining a machine translation model fit to a specific evaluation metric #REFR.", "predict": "The feature weights are optimized by minimum error rate training (MERT) #REFR on the training data."}
{"labels": "Pseudo-word evaluations are currently used to evaluate a variety of language modeling tasks #OTHEREFR; #REFR.", "predict": "We used the Stanford parser #REFR to parse the corpus."}
{"labels": "Statistical machine learning methods such as hidden Markov models #OTHEREFR; #REFR have become popular approaches to address the text extraction problem.", "predict": "The data was used in a number of previous studies #OTHEREFR; #REFR."}
{"labels": "The advantage of using POS tags rather than words is that their probabilities can be estimated much more accurately and, consequently, more accurate prediction of wordreading time is possible #OTHEREFR; #REFR.", "predict": "We use the following features for the dependency parsing model: 1. 2. 3. 4. 5. 6. 7. 8. 9. 9. 10. 11. 11. 11. 11."}
{"labels": "The second line of research uses comparable or bilingual corpora as the?pivot? that binds paraphrases together #OTHEREFR; #REFR.", "predict": "#REFR proposed a method to calculate the confidence in the parses based on the number of sentences in the corpus for which the parse is correct."}
{"labels": "These rules can be designed manually #OTHEREFR; #REFR.", "predict": "#REFRb) proposed a statistical approach to the translation of English into Spanish."}
{"labels": "#REFR adapt the technique of supertagging #OTHEREFR to CCG, using a standard maximum entropy tagger to assign small sets of supertags to each word.", "predict": "This approach is similar to the one used in #REFR."}
{"labels": "It also exploits the classification given by the COMLEX lexicon #REFR in order to calculate the deep-subject of infinitive verbs.", "predict": "Our approach is similar to that of #REFR, who proposed to use the same feature set in a new feature space."}
{"labels": "Recently, studies have explored dialog act tagging in written interactions such as emails #OTHEREFR; #REFRb), instant messaging #OTHEREFR.", "predict": "#REFR."}
{"labels": "A number of relation extraction kernels have been proposed, including dependency tree kernels #OTHEREFR; #REFR.", "predict": "In this paper, we focus on the problem of automatic extraction of semantic roles from text, which is also known as semantic role labeling #REFR."}
{"labels": "For one, it allows a tight correspondence between syntax and semantics by letting constituent structure express argument structure #REFR.", "predict": "The results of the second experiment are similar to those of the first one, with 90.3% accuracy on the test set, and a BLEU score of 0.7237 on the test set (as reported by #REFR)."}
{"labels": "Recently, there have been two promising research directions for improving SMT and its evaluation: #OTHEREFR, and (b) by going beyond the sentence-level, e.g., translating at the document level #REFR.", "predict": "#REFR present a system that uses a set of feature vectors to extract the most likely description for each word."}
{"labels": "The k?means algorithm is used for clustering the contexts, where the number of clusters is automatically discovered using the Adapted Gap Statistic #REFR.", "predict": "A similar idea is proposed in #REFR."}
{"labels": "One type of approach uses information extraction techniques such as pattern matching that use strong predictions on the content and attempt to fill templates derived from a model of the domain (e.g. #REFR), thus not giving too much importance to syntactic structure.", "predict": "The results of our experiment are comparable to those reported by #REFR."}
{"labels": "The mapping from a word alignment to the set of licensed phrase pairs pi(a) is based on the standard rule extraction procedures used in most modern statistical systems #REFR, but extended to handle possible links #OTHEREFR.", "predict": "In the field of dependency parsing, many approaches have been proposed for this task #OTHEREFR; #REFR."}
{"labels": "Word alignment and tokenization can also be optimized by maximizing the likelihood of bilingual corpus #REFR.", "predict": "In addition to the two methods we report here, there are also other methods that attempt to use the data from the same corpus #REFR."}
{"labels": "It is also interesting to note that the best result on the validation set for estimation 4We measured significance of all the experiments in this paper with the randomized significance test #REFR. of the loss with data-defined kernels (12) and (13) was achieved when the parameter A is close", "predict": "The first is the?time? approach #REFR."}
{"labels": "The binarization method used by #REFR can cover many non-constituent rules also, but not all of them.", "predict": "We follow #REFR and consider a single?i? for the?i? in the sentence."}
{"labels": "In contrast, approaches to WSD attempt o take advantage of many different sources of information #OTHEREFR); it seems possible to obtain benefit from sources ranging from local collocational clues #REFR to membership in semantically or topically related word classes #OTHEREFR; and disambignation seems highly lexical", "predict": "We also use the algorithm described in #REFR for detecting phrase alignments."}
{"labels": "One option would be to leverage unannotated text #OTHEREFR; #REFR.", "predict": "This is in contrast to previous work which only focused on the role of lexical resources #OTHEREFR; #REFR."}
{"labels": "Initially all sentences are pre-processed by the CoreNLP #OTHEREFR; #REFR suite of tools, a process that includes named entity recognition, normalization, part of speech tagging, lemmatization and stemming.", "predict": "#REFR have developed a statistical machine translation system for Chinese to English translation, which is based on a general-purpose statistical machine translation system."}
{"labels": "Our data source is the German NeGra treebank #REFR.", "predict": "A similar method was proposed by #REFR."}
{"labels": "Automatic detection of such argument alternations is important to acquisition of verb lexical semantics #REFR, and moreover, may play a role in automatic processing of language for applied tasks, such as question-answering #OTHEREFR.", "predict": "This is similar to the approach used in #REFR."}
{"labels": "Only for the Machine Translation task, #REFR report several results using different Arabic segmentation schemes.", "predict": "The use of word alignments in SMT is a common practice in machine translation #REFR."}
{"labels": "Next, other research efforts utilized the three categories into which various types of subordinate clauses are hierarchically classified based on the?scope-embedding preference? of Japanese subordinate clauses #OTHEREFR; #REFR.", "predict": "For example, #REFR proposed an unsupervised approach to the extraction of verb categories."}
{"labels": "This is because in citations, the discussion of the paper cited is usually mixed with the content of the paper citing it, and sometimes also with discussion about other papers cited #REFR.", "predict": "The use of such techniques in natural language processing has been studied for various tasks such as lexical similarity #OTHEREFR; #REFR, named entity recognition #OTHEREFR."}
{"labels": "The work of #OTHEREFR; #REFR focuses on manually constructing several lexica and rules for both polar words and related content-word negators, such as?prevent cancer?, where prevent reverses the negative polarity of cancer.", "predict": "We used the Stanford Parser #REFR to generate the parse trees for each language."}
{"labels": "An appealing alternative to a similar approximation to the above would use loopy belief propagation to efficiently approximate the marginals #REFR.", "predict": "For example, #REFR used a set of features including the number of words, number of characters, number of characters in the target language, and a list of words in the target language."}
{"labels": "Finally, a few efforts #OTHEREFR; #REFR have tried to translate sentences into formulas of first-order logic, in order to test logical entailment with a theorem prover.", "predict": "We use the Stanford parser #REFR to parse the corpus."}
{"labels": "Therefore, we prepare single bilingual signs for expressing their truth conditions if at least one of the languages has lexical items \\[#REFR\\].", "predict": "#REFRb) have proposed a method for identifying the most likely sequence of syntactic elements in a sentence."}
{"labels": "#REFR use shift-reduce parsing to impose ITG #OTHEREFR constraints on phrase permutation.", "predict": "The results are reported in terms of BLEU #REFR, TER #OTHEREFR."}
{"labels": "Similar tagsets are used by other studies on grammar induction and projection #REFR.", "predict": "In the literature, the goal of language acquisition has been divided into two categories: one is the acquisition of the ability to learn the syntax of a target language #OTHEREFR; #REFR; #OTHEREFR."}
{"labels": "A variety of features have been explored for ERD in previous research #OTHEREFR; #REFR.", "predict": "In this paper we explore the use of an N-best list for dependency parsing, following the approach of #REFR."}
{"labels": "However, it is fair to compare our work against other approaches which have attempted to disambiguate all content words in a text against some standard lexical resource, such as #REFR, #OTHEREFR.", "predict": "We compare our system with the 10-best systems in the CoNLL shared task on dependency parsing #REFR."}
{"labels": "This feature set is very close to that used in #REFR, but not identical.", "predict": "The second set of experiments was conducted with a method that combines the 13 different features described in #REFR and a set of additional features obtained by using the same set of feature extraction methods."}
{"labels": "The inside weight w i and the outside weight w o in the active items deserve more attention since this is the only difference compared to #REFR.", "predict": "The feature weights were tuned with MERT #REFR on the development set using the best-first algorithm."}
{"labels": "Various recent attempts have been made to include non-local features into graph-based dependency parsing #REFR.", "predict": "For example, the use of syntactic information to enhance the performance of statistical machine translation systems #OTHEREFR; #REFR."}
{"labels": "This feature set is reminiscent of the featurized representation of #REFR.", "predict": "#REFR."}
{"labels": "For example, a popular approach to reduce annotation effort is bootstrapping from seed examples #OTHEREFR; #REFR.", "predict": "We used the tagger #REFR and the parser #OTHEREFR to extract the POS tags for the sentences in the test set."}
{"labels": "These efforts have been met with some success in evaluations such as phrase similarity tasks #OTHEREFR; #REFR, sentiment prediction #OTHEREFR.", "predict": "The algorithm is similar to the one used by #REFR."}
{"labels": "Our use of an LSVM to assign credit during joint training differs substantially from previous LSVM applications, which have induced latent linguistic structures #OTHEREFR or sentence labels #REFR.", "predict": "To build a dependency parser, we use the Stanford dependency parser #REFR."}
{"labels": "The two most popular algorithms are McDonald?s MST- Parser #REFR and Nivre?s Malt- Parser #OTHEREFR.", "predict": "The tagger was trained on the Penn Treebank #REFR."}
{"labels": "#REFR developed a method in which they first identify (by means of affixes rules) a set of positive/negative words which act as seeds, then used a Roget-like thesaurus to mark the synonymous words for each polarity type and to generalize from the seeds.", "predict": "In this paper, we compare the results of two models that are similar to the approach of #REFR."}
{"labels": "We follow the candidate-ranking model proposed by #REFR.", "predict": "The use of these resources in the literature is extensive, and they are widely used in various NLP tasks such as machine translation #OTHEREFR; #REFR, and text summarization #OTHEREFR."}
{"labels": "Recent randomized language models #REFR make use of Bloom filter like structures to map n-grams to their associated probabilities or counts.", "predict": "In recent years, many research groups have developed techniques to identify and collect a large collection of linguistic knowledge sources #OTHEREFR; #REFR."}
{"labels": "#REFR introduced the concept of lexical weighting to check how well words of the phrase translate to each other.", "predict": "In this paper we present the second version of the 1993 paper by #REFR."}
{"labels": "Much work has been done on automatic Arabic diacritization #OTHEREFR; #REFR.", "predict": "For the second part of the work, #REFR proposed a method to calculate the number of word alignments for a sentence pair."}
{"labels": "This kind of supervision is similar to the seeding in bootstrapping literature #OTHEREFR or prototype-based learning #REFR.", "predict": "In the second and third sections we show the results of our system in the context of the 1998 and 2001 shared tasks #REFR, respectively."}
{"labels": "In our system, the well-known forward maximum matching algorithm #REFR is implemented.", "predict": "The best results are achieved by the method described in #REFR."}
{"labels": "The wordlevel sentiment annotation is to utilize the polarity annotation of words in each sentence and summarize the overall sentiment of each sentimentbearing word to infer the overall sentiment within the text #OTHEREFR; #REFR.", "predict": "The work of #REFR is a major example of this."}
{"labels": "This alignment matrix contains scores for all word correspondences in the sentence pair and can be created using GIZA++ #OTHEREFR or the Berkeley aligner #REFR.", "predict": "The first is the model of #REFR, which uses a single set of features for all language pairs."}
{"labels": "It has already been proposed for phrase-based #OTHEREFR, hierarchical #REFR, and syntax-based #OTHEREFR systems.", "predict": "For this reason, we have chosen to perform the same analysis as #REFR."}
{"labels": "Class-based approaches #OTHEREFR and #REFR are more promising: the implied clustering also tackles the data sparseness difficulties, but mainly they produce selectional constraints hat have a direct semantic interpretation.", "predict": "The same approach has been used for a number of other languages #REFR."}
{"labels": "In contrast, #REFR show that parser agreement is a strong indicator of parse quality, and in parser domain adaptation, Sagae and Tsujii #OTHEREFR use agreement between parsers to choose which automatically parsed target domain items to add to the training set.", "predict": "#REFRb) proposed an unsupervised approach to the disambiguation of verb-object relations."}
{"labels": "For comparison, we also include results for a setting that only uses word forms (Forms), which was the baseline for previous work on French dependency parsing #REFRb).", "predict": "In #REFR, the algorithm is applied to the data from the CoNLL shared task on NLP."}
{"labels": "In recent years discriminative probabilistic models have been successfully applied to a number of information extraction tasks in natural language processing #OTHEREFR, noun phrase chunking #REFR and information extraction from research papers #OTHEREFR.", "predict": "We use the Stanford parser #REFR to extract lexical information from the training corpus."}
{"labels": "These records are also known as field books and reference sets in literature #REFR.", "predict": "This is similar to the method described in #REFR."}
{"labels": "That parsing model has since been extended to make unsupervised learning more feasible #OTHEREFR; #REFRb).", "predict": "5.1.1 Semantic Classification In the past, a number of approaches have been proposed to automatically classify the meaning of a word into a semantic class #OTHEREFR; #REFR."}
{"labels": "This is also the task addressed by other WSD research such as #OTHEREFR; #REFR.", "predict": "In particular, the word-aligned data is used to train the SMT models #OTHEREFR, #REFR and #OTHEREFR."}
{"labels": "Statistical data about these various cooccurrence r lations is employed for a variety of applications, uch as speech recognition #OTHEREFR; #REFR.", "predict": "This is in line with the findings of #REFR, who found that for a given sentence pair, the number of possible translations is higher for the sentence that is more frequent."}
{"labels": "He has achieved state-of-the art results by applying M.E. to parsing #OTHEREFR, and sentence-boundary detection #REFR.", "predict": "#REFR)."}
{"labels": "Among the machine learning algorithms studied, rule based systems have proven effective on many natural language processing tasks, including part-of-speech tagging #OTHEREFR, message understanding #REFR, discourse tagging #OTHEREFR.", "predict": "The first step of the approach was to use the?unsupervised? approach of #REFR."}
{"labels": "Rather than relying on volunteers or gamification, NLP research into crowdsourcing translation has focused on hiring workers on the Amazon Mechanical Turk (MTurk) platform #REFR.", "predict": "To address this, several researchers have proposed new models for word sense disambiguation, such as #OTHEREFR, #REFR, and #OTHEREFR."}
{"labels": "Other researchers #OTHEREFR; #REFR have reported performance gains in translation by allowing deviations from monotone word and phrase order.", "predict": "Semantic parsing has been extensively studied in the past, and many techniques have been proposed to identify the semantic relationships between sentences #OTHEREFR; #REFR."}
{"labels": "In addition, timeline summarization techniques #OTHEREFR and some event-event ordering models #REFR also rely on the timestamps.", "predict": "This is in contrast to #REFR who find that the most accurate models are those that do not rely on a pre-trained word alignment, but instead use a simple word alignment of the target language and the source language."}
{"labels": "For example, a memorization feature is a word pair composed of the head nouns of the two NPs involved in an instance #REFR.", "predict": "4.1.1 Syntax In our work, we focus on the syntax of a sentence, i.e., the syntax of a sentence in the form of a syntactic structure, such as a tree #OTHEREFR; #REFR."}
{"labels": "Experiments have been made on the automatic acquisition of subcategorization frames since mid 1990s #OTHEREFR; #REFR.", "predict": "This work is similar to that of #REFR who explore the use of multiple language resources for English language processing."}
{"labels": "Fortunately, there is a growing body of work on genre-based text classification, including #OTHEREFR; #REFR.", "predict": "The system has been trained on the same data used by #REFR."}
{"labels": "This assumption, or its minor relaxations, is relatively standard in work on unsupervised semantic parsing tasks #REFR.", "predict": "#REFR."}
{"labels": "Other research has introduced the notion of identifying concepts in the input text #REFR, using a set cover algorithm to attempt to include as many concepts as possible.", "predict": "This method is widely used in the literature #OTHEREFR; #REFR."}
{"labels": "Early work on automatically inducing semantic relations between words, starting with #REFR, uses textual patterns.", "predict": "The algorithm for this problem is described in #REFR."}
{"labels": "Experiments in both #OTHEREFR and #REFR find no conclusive winner among early fusion, additive late fusion, and multiplicative late fusion.", "predict": "The approach used by #REFR is based on the idea of generating a large number of potential translations from a given sentence and using the most likely translations as the final ones."}
{"labels": "First, as in #REFR, we stipulate that some attributes of entities are more important than others, and that some words more naturally describe those attributes.", "predict": "In order to compute the probability of each word pair, we used the Stanford tagger #REFR, which is an automatic parser that is available for use at the web."}
{"labels": "Active learning has been shown, for a number of different NLP tasks, to reduce the number of manually annotated instances needed for obtaining a consistent classifier performance #OTHEREFR; #REFR.", "predict": "Our work is closely related to the work on the analysis of sentence-level discourse relations #OTHEREFR; #REFR."}
{"labels": "Therefore, SVMs have shown good performance for text categorization #OTHEREFR, chunking #REFR, and dependency structure analysis #OTHEREFR.", "predict": "For example, #REFR use an unsupervised method to learn the phrase-structure relationship between words."}
{"labels": "First, we briefly introduce our method for constructing NCFs from raw corpora proposed in #REFR.", "predict": "In addition to the automatic evaluation methods, we evaluate the system with human evaluation by testing the system on a test set with human-annotated text, using a manual evaluation method #REFR."}
{"labels": "Traditionally, broad coverage has always been considered to be a desirable property of a grammar: the more linguistic phenomena are treated properly by the grammar, the better results can be expected when applying it to unrestricted text #OTHEREFR; #REFR).", "predict": "#REFR."}
{"labels": "Common combination methods include the union or intersection of directional alignments, as well as heuristic interpolations between the union and intersection like grow-diag-final #REFR.", "predict": "Our results show that using a simple feature set of?1-gram features? #REFR provides a good performance, which is close to that of the traditional SVM, and is not so close to that of the SVM?s without the feature set."}
{"labels": "Following #REFR, we use an n-best list of 10000 sentences but we do not initially tune the negation feature using MERT or interpolate it with other features.", "predict": "#REFR)."}
{"labels": "WASP #REFR is a model motivated by statistical synchronous parsing-based machine translation #OTHEREFR.", "predict": "To reduce the number of features used, we use the 1000 most frequent words in the corpus, which were used by #REFR to improve the performance of the model."}
{"labels": "The resource presented in #REFR uses a similar binomial annotation for single words; another interesting resource is WordNetAffect #OTHEREFR but it labels words senses and it cannot be used for the prior polarity validation task.", "predict": "Semantic roles are often used in NLP tasks such as question answering #OTHEREFR, and machine translation #REFR."}
{"labels": "Previous approaches #OTHEREFR; #REFR have performed this task by modifying the type vector for T to the context s and then comparing the resulting vector T? to the type vector of a paraphrase candidate P.", "predict": "The model is based on the work of #REFR."}
{"labels": "The method #OTHEREFR aims to detect omission-type and replacement-type errors and transformation-based leaning is employed in #REFR to learn rules to detect errors for speech recognition outputs.", "predict": "2We follow #REFR in using the 2-gram language model for the training of the 1-gram language model."}
{"labels": "In recent years, conditional random fields #OTHEREFR and information extraction from research papers #REFR.", "predict": "The use of?word sense disambiguation? #REFR and?word sense disambiguation? #OTHEREFR for machine translation is another example."}
{"labels": "This is a significant improvement with respect to previous results achieved by the pure distributional model reported in #REFR.", "predict": "#REFR."}
{"labels": "As a consequence, finding the highest scoring parse tree is a provably hard combinatorial inference problem #REFR.", "predict": "4.2.1 Data Semantics The most common method for evaluating semantic similarity between entities is the word-based method #OTHEREFR; #REFR."}
