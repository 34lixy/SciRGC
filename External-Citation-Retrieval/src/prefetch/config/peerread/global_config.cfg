{
    ## 这些是在你想要在自定义数据集上训练模型时需要指定的参数
    "prefetch_model_folder":"../../model/prefetch-peerread/peerread/",
    "paper_database_path":"../../data/peerread/papers.json",
    "context_database_path":"../../data/peerread/contexts.json",
    "train_corpus_path":"../../data/peerread/train_with_prefetched_ids.json",
    "log_folder":"../../log/prefetch-peerread/peerread/",
    "prefetch_embedding_path":"../../embedding/prefetch/peerread/paper_embedding.pkl",
    "input_corpus_path_for_get_prefetched_ids_during_training":"../../data/peerread/train.json",
    "output_corpus_path_for_get_prefetched_ids_during_training":"../../data/peerread/train_with_prefetched_ids.json",
    "input_corpus_path_for_validation":"../../data/peerread/val.json",
    "output_corpus_path_for_validation_with_prefetched_ids":"../../data/peerread/val_with_prefetched_ids.json",
    "input_corpus_path_for_test":"../../data/peerread/test.json",
    
    "max_num_samples_per_batch":100, # 一个批次内的最大查询/文档数量。这取决于所有GPU的总GPU内存。如果你有1个GPU（11 GB），通常设置为100
    "n_device":1, # 可用的GPU数量
    "max_num_loops_for_training_updating_embedding_and_prefetched_ids":5, # 这将确定训练循环何时自动停止。对于大型数据集，此值应足够大（例如100）。对于小数据集，如ACL-200，5个循环将产生足够好的结果。
    "num_training_examples_with_prefetched_ids_for_reranking":10000, # 我们获取最终预取id的训练示例数量，并使用它们来训练重排系统。请注意，我们可能不需要所有训练示例来微调重排器。如果值为0，则表示我们获取所有训练示例的预取id，并使用它们来训练重排器。这里我们以10000作为示例
    "num_val_examples_with_prefetched_ids_for_reranking":1000, # 我们获取最终预取id的训练示例数量，并使用它们来训练重排系统。

    
    
    ## 这些是通常保持不变的参数
    "print_every":500,  ## 每隔一定迭代报告一次训练损失
    "save_every":5000,  ## 每隔一定迭代保存一次检查点
    "max_num_iterations":5000,  ## 在一个训练 -> 更新嵌入 -> 更新预取id循环中，在训练阶段的总训练迭代次数，在大数据集上设置为较大的值（例如10000），例如arXiv
    
    "K_list":[10,20,50,100,200,500,1000,2000], # 这是我们感兴趣的前K个值。
    "top_K_prefetched_ids_for_mining_hard_negative":100,
    "top_K_prefetched_ids_for_reranking":2000, ## 我们首先预取2000个候选项，然后用重排器对它们进行重排
    
    "num_papers_with_updated_embeddings_per_loop":0,  ## 当论文数据库很大，例如包含数百万篇论文时，我们可以只重新计算部分论文数据库，并使用这部分更新的嵌入索引来预取论文，并从中挖掘困难的负面影响，值0表示更新所有论文嵌入
    "num_training_examples_with_updated_prefetched_ids_per_loop":50000, ## 当训练集非常大时，我们可以只更新从整个训练数据集中随机抽样的部分训练示例的预取id，并使用它们在下一个循环中训练文本编码器
    "num_val_examples_per_loop":0,  ## 我们可以仅使用部分验证集来评估val性能。验证的目的仅是以有效的方式提供有关预取性能的粗略信息。值0表示使用整个验证集来评估性能
    "unigram_words_path":"../../model/glove/vocabulary_200dim.pkl",
    "unigram_embedding_path":"../../model/glove/unigram_embeddings_200dim.pkl",
    "train_log_file_name": "train.log",
    "val_log_file_name":"validate_NN.log",
    "test_log_file_name":"test_NN.log",
    ## 对于每个查询，我们获取1篇正向论文（由查询引用的论文），3篇预取但未引用的论文和1篇随机抽样的论文。我们继续将更多查询添加到批次中，直到达到max_num_samples_per_batch
    "max_n_positive": 1,  
    "max_n_hard_negative": 3,
    "max_n_easy_negative": 1,
    
    "num_workers": 2,
    "initial_learning_rate": 1e-4,
    "l2_weight": 1e-5,
    "dropout_rate": 0.1,
    "moving_average_decay": 0.999,
    "base_margin": 0.05,
    "similarity": "cosine",
    "positive_irrelevance_levels":[1,2],
    "max_num_checkpoints": 20,
    
    ## 以下部分与文本编码器的参数有关
    "embed_dim": 200,  
    "num_heads": 8,
    "hidden_dim": 1024,
    "max_seq_len": 512,
    "max_doc_len": 3,
    "n_para_types": 100,
    "num_enc_layers": 1,
    
    "document_title_label": 0,
    "document_abstract_label": 1,
    "document_fullbody_label": 2,
    
    "citation_title_label": 0,
    "citation_abstract_label": 1,
    "citation_fullbody_label": 2,
    "citation_context_label": 3,
    
    "padding_paragraph_label": 10,
    "fused_label": 0
    
}
